++ 3dREMLfit: AFNI version=AFNI_18.3.16 (Dec 11 2018) [64-bit]
++ Authored by: RWCox
++ GOFORIT ==> Matrix de-singularization is engaged!
++ Number of OpenMP threads = 15
++ No mask ==> computing for all 10242 voxels
[7m** ERROR:[0m matrix column #255 is all zero!?
[7m** ERROR:[0m matrix column #264 is all zero!?
[7m*+ WARNING:[0m You said to GOFORIT, so here we GO!
 +          Note that a bunch of further WARNINGs will be generated below.
++ Denominator DOF increased from 654 to 656 to allow for all zero columns
++ -----  matrix condition (1296x642):  6.83509  ++ VERY GOOD ++
[7m*+ WARNING:[0m !! in  matrix:
 * Largest singular value=2.14832
 * 2 singular values are less than cutoff=2.14832e-07
 * Implies strong collinearity in the matrix columns! 
++  matrix singular values:
   4.54055e-08   6.84136e-08     0.0459843     0.0957788      0.108536
      0.128518      0.165917      0.172626      0.190833       0.20285
      0.242388      0.258556       0.25975      0.261331      0.261696
      0.262054      0.265042      0.273322      0.284963       0.29391
      0.311209      0.326819      0.330065      0.340233      0.343883
      0.347556      0.349472      0.354388      0.355122      0.363721
      0.367171      0.375347      0.382172      0.383664      0.388345
      0.391797      0.394656      0.395168       0.39763      0.398255
      0.403787      0.406932      0.412609      0.414614      0.419198
      0.423989      0.432332      0.433293      0.434295      0.438231
      0.441751      0.443861      0.448033      0.450773      0.454962
       0.46077      0.462618      0.466375       0.47139      0.474053
      0.478938      0.480839      0.481904      0.484438      0.486133
      0.487923      0.489638      0.490833      0.493935      0.496292
      0.498181       0.50003      0.503246       0.50604      0.510372
      0.512274      0.513915      0.515278       0.51598       0.51914
      0.521693      0.524014      0.527493      0.532364      0.533786
      0.535572      0.537415      0.538615      0.540568      0.543339
      0.547016      0.550501      0.552029      0.556389       0.56007
      0.564119       0.56675      0.568763      0.571375      0.572909
      0.576904      0.579751      0.582264      0.583839      0.584299
      0.587147      0.589816      0.592112      0.594001      0.597441
      0.598196      0.600666      0.603264       0.60465      0.604947
      0.612242      0.614189      0.615063      0.616677      0.620127
      0.620575      0.622973      0.624945      0.627925      0.628731
      0.630408      0.633305      0.637655      0.639191      0.643406
      0.645623      0.649648      0.650746      0.652356      0.654154
      0.655747      0.660985      0.663369      0.664492      0.666338
      0.668502      0.670383      0.671848      0.674769      0.676575
      0.678124      0.679547      0.682699      0.686638      0.692128
      0.693384      0.694095      0.695372      0.697191      0.698256
      0.700178      0.701828      0.703381      0.708101      0.709213
      0.710705      0.714379      0.716132      0.717541      0.719682
      0.722793      0.725395       0.72733      0.728983      0.731934
      0.732464      0.734359       0.73811      0.740425      0.741065
      0.744687      0.745468      0.748135      0.750025        0.7535
      0.755449      0.758205      0.759869      0.761942      0.764045
      0.766866      0.768789      0.769524      0.772583      0.775361
      0.777972      0.779955      0.781515      0.783613      0.785526
      0.785707      0.787418      0.789203       0.79265      0.794783
      0.795312      0.799518      0.800171      0.802384      0.804889
      0.806443      0.810201      0.812363      0.814668      0.818365
       0.81954      0.821774        0.8227      0.826189      0.828472
      0.829197      0.831201      0.834525       0.83536        0.8383
      0.838713      0.840904      0.844483      0.845758      0.846748
       0.84943      0.850706      0.851678       0.85286      0.853619
      0.856152      0.858056      0.859183      0.860552      0.863386
      0.864751      0.868251       0.87022      0.872754      0.874883
      0.877563      0.879074      0.881644      0.883003      0.884315
      0.885717      0.888607      0.891792      0.893513      0.895703
      0.896385      0.898736      0.900097       0.90079      0.901818
      0.903531      0.905309      0.908158      0.908561      0.909627
      0.911568      0.914783      0.915678      0.916563      0.918447
       0.91948      0.920831       0.92368      0.925293      0.926499
      0.928932      0.929953       0.93088       0.93231      0.935003
      0.936465      0.938596      0.940214      0.941716      0.944236
      0.944862      0.946635       0.94956      0.950898      0.956257
       0.95952      0.960421      0.961287       0.96346      0.966007
      0.967728      0.968997      0.971898      0.975805      0.977127
      0.978571      0.980225      0.981517      0.984209      0.985618
      0.988294      0.989078      0.991557      0.993284      0.994735
      0.996258      0.996857      0.998791      0.999231      0.999552
      0.999991      0.999993      0.999994      0.999995      0.999996
      0.999997      0.999998      0.999998      0.999999      0.999999
             1             1             1             1             1
             1             1             1             1             1
             1             1             1             1       1.00001
       1.00004        1.0001       1.00025       1.00065       1.00087
       1.00184       1.00232        1.0029       1.00389       1.00445
       1.00541       1.00705       1.00848       1.00934       1.01373
       1.01468       1.01735       1.01947       1.02049       1.02116
        1.0225        1.0232       1.02428       1.02579       1.02816
       1.02982       1.03164       1.03351       1.03556       1.03596
       1.03761       1.03852       1.04141       1.04164       1.04292
       1.04677       1.04921       1.05178       1.05301       1.05383
       1.05411       1.05502       1.05743       1.06041       1.06106
        1.0633       1.06402       1.06481        1.0673       1.06857
       1.06937       1.07142        1.0722       1.07269       1.07603
       1.07651       1.07785       1.07957       1.08001       1.08161
       1.08387       1.08428       1.08501       1.08664       1.08794
       1.09048        1.0913       1.09259       1.09524       1.09605
       1.09798       1.09848       1.10085       1.10145       1.10317
       1.10542       1.10623       1.10965       1.11034        1.1138
       1.11477       1.11666       1.11804       1.11891       1.11967
       1.12288       1.12397       1.12531       1.12639        1.1272
       1.12831       1.12924       1.13051       1.13146        1.1321
       1.13384       1.13453       1.13618        1.1372       1.13931
       1.13972       1.14066       1.14122       1.14193       1.14389
       1.14553       1.14636       1.14801        1.1505        1.1523
       1.15349       1.15428       1.15569       1.15781       1.15855
       1.16183       1.16288       1.16409       1.16616       1.16757
        1.1676       1.17014       1.17185       1.17307       1.17481
       1.17644       1.17811       1.18099       1.18261       1.18574
       1.18623       1.18787       1.18857       1.19058       1.19169
       1.19295         1.194       1.19444       1.19768       1.19938
       1.20033       1.20135        1.2023       1.20399       1.20614
       1.20702       1.20878       1.20932       1.21102       1.21224
       1.21334       1.21416       1.21468       1.21599       1.21673
       1.21819        1.2196        1.2217       1.22236       1.22361
       1.22386       1.22695       1.22785       1.22925       1.23076
       1.23132       1.23246       1.23391       1.23633       1.23774
       1.23901       1.24123       1.24184       1.24422       1.24447
        1.2457       1.24717       1.24832         1.249       1.25078
       1.25241       1.25333       1.25495       1.25569       1.25658
        1.2577       1.25853       1.26052       1.26152       1.26331
        1.2646       1.26681       1.26729       1.26862       1.26953
       1.27133       1.27307        1.2738       1.27446       1.27557
       1.27765       1.27827       1.27905       1.27976       1.28065
       1.28209       1.28321       1.28523       1.28731       1.28753
       1.28946       1.28987       1.29062       1.29513       1.29606
       1.29818       1.29874       1.29992       1.30167       1.30348
        1.3037        1.3042       1.30692       1.30879       1.31079
       1.31097       1.31243       1.31327       1.31409       1.31463
        1.3161        1.3172       1.31844       1.31905       1.31976
        1.3203       1.32094       1.32151       1.32241       1.32373
       1.32393       1.32529       1.32586       1.32633        1.3272
       1.32798        1.3285       1.32921       1.33006       1.33064
       1.33144       1.33187       1.33261        1.3353       1.33749
       1.33857        1.3403       1.34088       1.34319       1.34441
       1.34558       1.34665       1.34876       1.34944       1.35059
       1.35139        1.3523       1.35477         1.356       1.35634
       1.35656       1.35779       1.35807       1.35882       1.35933
       1.36026       1.36165        1.3631       1.36437       1.36709
       1.36751       1.36905       1.37061       1.37082       1.37191
       1.37525       1.37742       1.37862       1.38029       1.38702
       1.38909        1.3893        1.3898       1.38984       1.39006
       1.39049       1.39329       1.39506       1.40539       1.41645
       1.43717       1.44245       1.47854       1.51606       1.63805
       1.96802       2.14832
[7m*+ WARNING:[0m -GOFORIT ==> Charging ahead into battle!
 +                   ==> Check results carefully!
++ Editing GLT matrices for all zero X matrix columns
 + Removed 2 all zero rows from GLT matrix 'Full'; numerator DOF changes from 622 to 620
 + Removed 1 all zero row from GLT matrix 'l_1A'; numerator DOF changes from 19 to 18
 + Removed 1 all zero row from GLT matrix 'l_A1'; numerator DOF changes from 19 to 18
++ Loading input dataset into memory
 + masked off 888 voxels for being all zero; 9354 left in mask
++ starting REML setup calculations; total CPU=0.00 Elapsed=12.17
 + X matrix: 2.503% of elements are nonzero
[7m*+ WARNING:[0m -----
[7m*+ WARNING:[0m QR decomposition of [R]^(-1/2) [X] had 2 collinearity problems
[7m*+ WARNING:[0m -----
 + starting 15 OpenMP threads for REML setup
 + REML setup finished: matrix rows=1296 cols=642; 109*1 cases; total CPU=0.00 Elapsed=928.62
 +  average case bandwidth = 13.12
++ REML voxel loop: [15 threads]0123456789.0123456789.0123456789.0123456789.01234567
 + ARMA voxel parameters estimated: total CPU=0.00 Elapsed=983.26
++ GLSQ loop:0123456789.0123456789.0123456789.0123456789.0123456789.
 + GLSQ regression done: total CPU=0.00 Elapsed=1943.05
++ Output dataset /data/nil-external/ccp/freund/ub55/out/glms/DMCC9953810/RESULTS/Cuedts/baseline_aggressive1_EVENTS_censored_shifted/stats_var_DMCC9953810_L_REML.func.gii
++ Output dataset /data/nil-external/ccp/freund/ub55/out/glms/DMCC9953810/RESULTS/Cuedts/baseline_aggressive1_EVENTS_censored_shifted/errts_DMCC9953810_L_REML.func.gii
++ Output dataset /data/nil-external/ccp/freund/ub55/out/glms/DMCC9953810/RESULTS/Cuedts/baseline_aggressive1_EVENTS_censored_shifted/wherr_DMCC9953810_L_REML.func.gii
++ Output dataset /data/nil-external/ccp/freund/ub55/out/glms/DMCC9953810/RESULTS/Cuedts/baseline_aggressive1_EVENTS_censored_shifted/STATS_DMCC9953810_L_REML.func.gii
 + unloading input dataset and REML matrices
++ 3dREMLfit is all done! total CPU=0.00 Elapsed=1950.48
